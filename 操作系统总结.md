# 操作系统总结

## 1.什么是操作系统

1.操作系统(Operating System,OS)是管理计算机硬件和软件资源的程序，是计算机的基石

2.操作系统本质上是一个运行在计算机上的软件程序，用于管理计算机硬件和软件资源。

3.操作系统的存在屏蔽了硬件层的复杂性。

4.操作系统的内核(Kernel)是操作系统的核心部分，它负责系统的内存、硬件设备、文件系统、应用程序的管理。

![image-20210823144047603](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108231440683.png)

## 2.操作系统作用之接口

操作系统的功能之一是作为用户与计算机硬件系统之间的接口

分为：命令接口和程序接口。

**命令接口**：用户可以直接使用

**程序接口**：用户用程序间接使用

其中命令接口又分为联机命令接口和脱机命令接口。

联机命令接口：又称为交互式命令接口，适用于分时或实时系统，用户输入一条指令，操作系统就执行一条指令。

脱机命令接口：又称为批处理接口，由一组作业控制命令组成。用户输入一堆指令，操作系统就执行一堆指令且操作系统运行这些命令时，用户不可干预。(类似数据库的原子性)

**程序接口**：由一组系统调用(广义指令)组成

## 3.操作系统特征

### ![image-20210823170001023](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108231700122.png)

### 1.并发

并发：两个或多个事件在同一时间间隔内发生，这些事件在宏观上是同时发生的，在微观上是交替发生的， 操作系统的并发性指系统中同时存在着多个运行的程序。

并行：两个或多个事件在同一时刻发生

### 2.共享

指系统中的资源可以供内存中多个并发执行的进程共同使用

#### (1)互斥共享

某个资源在一段时间内只允许一个进程访问

临界资源

#### (2)同时共享

某个资源在一段时间内允许多个进程访问

分时共享，宏观上的同时，微观上还是交替进行访问

#### (3)并发性和共享性互为存在条件

### 3.虚拟

![image-20210823165908643](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108231659741.png)

操作系统的虚拟技术科归纳为：

- 时分复用技术：如处理器的分时共享
- 空间复用技术：如虚拟存储器

### 4.异步

多道程序环境允许多个程序并发执行，但由于资源有限，如cpu只有一个，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进。

## 4.系统调用

先了解用户态和系统态

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别

##### 用户态：用户态的进程可以直接访问用户程序的数据

##### 系统态：系统态的进程或程序几乎可以访问计算机的任何资源，不受限制

因此由用户态转向系统态就需要系统调用，就是在用户态的程序需要调用系统态级别的功能。

也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- 设备管理。完成设备的请求或释放，以及设备启动等功能。
- 文件管理。完成文件的读、写、创建及删除等功能。
- 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等功能。
- 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

## 5.进程和线程的区别

![image-20210823172138110](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108231723241.png)

## 6.进程状态

进程状态一般分为5种状态，和线程很像

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

![image-20210823172718935](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108231727135.png)

## 7.进程间的通信方式

- 管道(PIPE)

  1. 有名管道：一种半双工的通信方式，允许无亲缘关系的进程间通信

     - [ ] 优点：可以实现任意关系的进程间的通信

     - [ ] 缺点：长期存于系统中，使用不当容易出错

       ​			缓冲区有限

​          2.无名管道：一种半双工通信方式，只能在具有亲缘关系的进程间使用(父子进程)

​				优点：简单方便

​				缺点：局限于单向通信

​							只能创建在它的进程以及其有亲缘关系的进程之间

​							缓存区有限

- 信号量(Semaphore):一个计数器，可以用来控制多个线程对共享资源的访问

  优点：可以同步进程

  缺点：信号量有限

- 信号(Signal):一种比较复杂的通信方式，用于通知接收进程某个事件已经发生

- 消息队列(Message Queue):是消息的链表，存放在内核中并由消息队列标识符标识

  优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便。

  缺点：信息的复制需要额外消耗CPU的时间，不适宜于信息量大或操作频繁的场合

- 共享内存(Shared Memory):映射一段能被其他进程所访问的内存，这段内存由一个进程创建，但多个进程都可以访问。

  优点：无须复制，快捷，信息量大

  缺点： 1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题

     			 2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信

- 套接字(Socket):可用于不同计算机间的进程通信

  优点：1.传输数据为字节级，传输数据可自定义，数据量小效率高

  ​			2.传输数据时间短，性能高

  ​			3.适合于用户端和服务器端之间的信息实时交互

  ​			4.可以加密，数据安全性强

  缺点：需对传输的数据进行解析，转化成应用级的数据。

## 8.线程间的同步方式

线程同步是两个或多个共享关键资源的线程的并发执行。因该同步线程避免关键资源的使用冲突。

线程同步方式由如下四种：

- 锁机制：包括互斥锁(mutex)、读写锁(reader-writer lock)、自旋锁(spin lock)、条件变量(condition)
  - 互斥锁(mutex):提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁(reader-writer lock)：允许多个线程同时读共享数据，而对写操作互斥。
  - 自旋锁(spin lock)：循环检测保持者是否已经释放锁。
  - 条件变量(condition)：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)
  - 无名信号量
  - 有名信号量
- 信号机制(Signal):类似进程间的信号处理
- 屏障(barrier)：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

## 9.进程调度算法

为了确定进程执行的顺序以实现CPU的最大利用率，有以下进程调度算法：

**先到先服务调度算法(First come first sever, FCFS):**从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

**短作业优先(Shortest Job First, SJF):**从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

**高响应比优先(Highest Response Ratio Next, HRRN):**在每次调度时先计算各个作业/进程的响应比((等待时间+要求服务时间)/要求服务时间)，选择响应比最高的进程为其服务。

**时间片轮转(Round Robin, RR):**时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。

**优先级调度算法：**为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

**多级反馈队列调度算法：**前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

## 10.什么是死锁

多个进程可以竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。有时，如果所申请的资源被其他等待进程占有，那么该等待进程有可能再也无法改变状态。这种情况成为**死锁**。

## 11.产生死锁的四个条件

如果系统中四个条件同时成立，就能引起死锁

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

## 12.内存管理主要做什么

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

![image-20210824153308263](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241533474.png)

## 13.内存管理的方式有哪些

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理**：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

![image-20210824154058303](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241540374.png)

## 14.快表和多级页表

这两个东西分别解决页表管理中很重要的两个问题：

- 虚拟地址到物理地址的转换要快。
- 解决虚拟地址空间大，页表也会很大的问题。

**快表：**又称为联想寄存器(TLB)，为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

![image-20210824154722133](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241547331.png)

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。

**多级页表：**引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。

![image-20210824155000626](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241550807.png)

## 15.分页和分段机制的联系与区别

1. 共同点
   - 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. 区别
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

## 16.逻辑地址和物理地址

也就是相对地址和绝对地址的关系。

**物理地址**：加载到内存地址寄存器中的地址，内存单元的真正地址。在前端总线上传输的内存地址都是物理内存地址，编号从0开始一直到可用物理内存的最高端。这些数字被北桥(Nortbridge chip)映射到实际的内存条上。物理地址是明确的、最终用在总线上的编号，不必转换，不必分页，也没有特权级检查(no translation, no paging, no privilege checks)。

**逻辑地址**：CPU所生成的地址。逻辑地址是内部和编程使用的、并不唯一。例如，你在进行C语言指针编程中，可以读取指针变量本身值(&操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址（偏移地址），不和绝对物理地址相干。

## 17. CPU寻址以及虚拟地址空间

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

![img](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241603106.png)

**为什么要有虚拟地址空间呢？**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

## 18.什么是虚拟内存

很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。**为什么可以这样呢？** 正是因为 **虚拟内存** 的存在，通过 **虚拟内存** 可以让程序拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

## 19.局部性原理

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

![image-20210824163134183](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241631385.png)

## 20.虚拟内存的技术实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

![image-20210824163231184](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241632352.png)

## 21.请求分页与分页式管理的区别

**主要区别：**程序的全部内存是否装入内存中，

请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。

它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

不管是上面那种实现方式，我们一般都需要：

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。

## 22.页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

**缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。
- **时钟置换算法(CLOCK)：**又称最近未使用算法(Not Recently Used, NRU)，通过给每一个访问的页面关联一个附加位(reference bit)，有些地方也叫做使用位(use bit)。他的主要思想是：当某一页装入主存时，将use bit置成1；如果该页之后又被访问到，使用位也还是标记成1。对于页面置换算法，候选的帧集合可以看成是一个循环缓冲区，并且有一个指针和缓冲区相关联。遇到页面替换时，指针指向缓冲区的下一帧。如果这页进入主存后发现没有空余的帧(frame)，即所有页面的使用位均为1，那么这时候从指针开始循环一个缓冲区，将之前的使用位都清0，并且留在最初的位置上，换出该桢对应的页。

![image-20210824164900781](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241649892.png)

![image-20210824164914647](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108241649747.png)

## 23.磁盘调度算法

一次磁盘读/写操作需要的时间：寻找时间+延迟时间+传输时间。

操作系统可以优化的是寻找时间。

- 先来先服务(FCFS)
- 最短寻找时间优先算法(SSTF)
- 扫描算法(SCAN)
- LOOK算法
- 循环扫描算法(C-SCAN)
- C-LOOK算法

![image-20210825145001943](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202108251450102.png)

## 24. 零拷贝技术

零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。针对操作系统中的设备驱动程序、文件系统以及网络协议堆栈而出现的各种零拷贝技术极大地提升了特定应用程序的性能，并且使得这些应用程序可以更加有效地利用系统资源。这种性能的提升就是通过在数据拷贝进行的同时，允许 CPU 执行其他的任务来实现的。

**避免数据拷贝**
①避免操作系统内核缓冲区之间进行数据拷贝操作。
②避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。
③用户应用程序可以避开操作系统直接访问硬件存储。
④数据传输尽量让 DMA 来做。

**将多种操作结合在一起**
①避免不必要的系统调用和上下文切换。
②需要拷贝的数据可以先被缓存起来。
③对数据进行处理尽量让硬件来做。

![image-20210910094333679](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202109100943830.png)

**优化前**

![image-20210910094346599](https://raw.githubusercontent.com/xjs-xrhm/Images/main/202109100943680.png)

**优化后**

## 25. 中断的类型

中断分为三类

1.外中断

​	由CPU外部引起的：I/O中断、时钟中断

2.内中断

​	来自CPU内部时间或程序引起的中断：程序非法操作、地址越界、浮点溢出

3.程序中使用了系统调用引起的

中断处理一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理由软件实施

## 26. 内部碎片和外部碎片

**内部碎片**

- 内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；
  内部碎片 是处于 （操作系统分配的用于装载某一进程的内存）区域内部 或页面内部 的存储块。占有这些区域或页面的进程并不使用这个 存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。
  单道连续分配只有内部碎片。 多道固定连续分配既有内部碎片，又有外部碎片。

**外部碎片**

- 外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。
- 外部碎片是处于任何两个已分配区域或页面之间的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。
